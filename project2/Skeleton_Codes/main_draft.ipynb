{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ad60ca",
   "metadata": {},
   "source": [
    "# Radar Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5145a2",
   "metadata": {},
   "source": [
    "## A Radar Classification Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a41617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import cvxpy as cp\n",
    "from cvxpy.atoms.affine.wraps import psd_wrap\n",
    "from read_data import *\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%       MGT - 418         %%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%      Convex Optimization - Project 2          %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%             2021-2022 Fall                    %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%      Learning the Kernel Function             %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89c9907",
   "metadata": {},
   "source": [
    "### (a) Read & Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bc34d0",
   "metadata": {},
   "source": [
    "**(5 points)** Read the data file ionosphere.data into memory by using the scriptsreaddata.pyorreaddata.m.Use the code skeletonsmain.ipnyb or main.m to randomly select 80% of the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729b41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = prepare_ionosphere_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b795ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_data import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cabc1712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0\n",
      "[[1.0 0.97588 -0.10602 0.94601 -0.208 0.92806 -0.2835 0.85996 -0.27342\n",
      "  0.79766 -0.47929 0.78225 -0.50764 0.74628 -0.61436 0.57945 -0.68086\n",
      "  0.37852 -0.73641 0.36324 -0.76562 0.31898 -0.79753 0.22792 -0.81634\n",
      "  0.13659 -0.8251 0.04606 -0.82395 -0.04262 -0.81318 -0.13832 -0.80975]]\n",
      "#1\n",
      "[[1.0 -0.205 0.2875 0.23 0.1 0.2825 0.3175 0.3225 0.35 0.36285 -0.34617\n",
      "  0.0925 0.275 -0.095 0.21 -0.0875 0.235 -0.34187 0.31408 -0.48 -0.08\n",
      "  0.29908 0.33176 -0.58 -0.24 0.3219 -0.28475 -0.47 0.185 -0.27104\n",
      "  -0.31228 0.40445 0.0305]]\n",
      "#2\n",
      "[[1.0 1.0 0.5782 1.0 -1.0 1.0 -1.0 1.0 -1.0 1.0 -1.0 1.0 -1.0 1.0 -1.0\n",
      "  1.0 -1.0 1.0 -1.0 1.0 -0.62796 1.0 -1.0 1.0 -1.0 1.0 -1.0 1.0 -1.0 1.0\n",
      "  -1.0 1.0 -1.0]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"#{}\".format(i))\n",
    "    # data_train, data_test, labels_train, labels_test\n",
    "    data_train, _, _, _ = train_test_split(data, labels, train_size=0.8, random_seed=i)\n",
    "    print(data_train[:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91059b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 35)\n",
      "Unique values in 2nd column: [0]\n",
      "(351, 34)\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "# just testing\n",
    "df = pd.read_csv('ionosphere.data', sep=\",\", header=None)\n",
    "data_array = np.array(df)\n",
    "print(np.shape(data_array))\n",
    "# delete the second row\n",
    "print(\"Unique values in 2nd column:\", np.unique(data_array[:,1]))\n",
    "data_array = np.delete(data_array, 1, 1)\n",
    "print(np.shape(data_array))\n",
    "print(round(np.shape(data_array)[0]*0.8))\n",
    "labels = data_array[:, -1]\n",
    "labels[labels == 'g'] = -1\n",
    "labels[labels == 'b'] = 1\n",
    "data_array = data_array[:, :-1]\n",
    "data_normalized = data_array / data_array.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396849b",
   "metadata": {},
   "source": [
    "- reference links\n",
    "\n",
    "    - https://stackoverflow.com/questions/3674409/how-to-split-partition-a-dataset-into-training-and-test-datasets-for-e-g-cros\n",
    "    - https://towardsdatascience.com/stop-using-numpy-random-seed-581a9972805f\n",
    "    - https://stackoverflow.com/questions/49555991/can-i-create-a-local-numpy-random-seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a016f",
   "metadata": {},
   "source": [
    "### (b) Define kernel function & Solve QCQP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f054940",
   "metadata": {},
   "source": [
    "**(15 points)** Define polynomial, Gaussian, and linear kernel function, and construct the kernel matrices $\\hat{K}^l,\\ l = 1,2,3$, for all training samples\n",
    "Solve the QCQP in (5) for $\\rho = 2$, $p = 2$, $\\sigma = 2$ and $c = \\sum_{l=1}^3 \\mathrm{tr}(\\hat{K}^l) $ with CVXPY and MOSEK in Python or with YALMIP and GUROBI in MATLAB, and record the optimal dualvariables $\\mu_1^*$, $\\mu_2^*$, and $\\mu_3^*$. Use the code skeletons `kernel_learning` (in `main.ipynb`) or `kernel_learning.m`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d5d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(x, y):\n",
    "    return np.inner(x, y)\n",
    "\n",
    "\n",
    "def gauss_kernel(x, y, sigma=0.5):\n",
    "    return np.exp(-np.sqrt(la.norm(x - y) ** 2 / (2 * sigma ** 2)))\n",
    "\n",
    "\n",
    "def poly_kernel(x, y, dimension=2, offset=1):\n",
    "    return (offset + np.inner(x, y)) ** dimension\n",
    "\n",
    "\n",
    "def compute_k_mat(X, kernel):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X is an n_tr x n_feat matrix.\n",
    "        kernel is a string with values 'linear', 'rfb', or 'poly'\n",
    "            'linear': k(u,v) = u'*v.\n",
    "            'gaussian':    k(u,v) = exp(-||u - v||^2 / (2*sigma)).\n",
    "            'poly':   k(u,v) = (1 + u'*v)**degree.\n",
    "            degree is a positive integer.\n",
    "    Output:\n",
    "        k_mat, an n_tr x n_tr matrix.\n",
    "    \"\"\"\n",
    "    n_samples, _ = X.shape\n",
    "    k_mat = np.zeros((n_samples, n_samples))\n",
    "    for i, x_i in enumerate(X):\n",
    "        for j, x_j in enumerate(X):\n",
    "            if kernel == \"linear\":\n",
    "                k_mat[i, j] = linear_kernel(x_i, x_j)\n",
    "            elif kernel == \"gaussian\":\n",
    "                k_mat[i, j] = gauss_kernel(x_i, x_j)\n",
    "            elif kernel == \"poly\":\n",
    "                k_mat[i, j] = poly_kernel(x_i, x_j)\n",
    "    return k_mat\n",
    "\n",
    "\n",
    "def compute_ks(x_mat):\n",
    "    \"\"\"compute all three kernel matrix\"\"\"\n",
    "    kernels = [\"poly\", \"gaussian\", \"linear\"]\n",
    "    k_mats = []\n",
    "    for k in kernels:\n",
    "        mat = compute_k_mat(x_mat, k)\n",
    "        k_mats.append(mat)\n",
    "    return k_mats\n",
    "\n",
    "\n",
    "def compute_g_mat(k_mat, y_vec):\n",
    "    n_tr = len(y_vec)\n",
    "    g_mat = np.zeros((n_tr, n_tr))\n",
    "    for i in range(n_tr):\n",
    "        for j in range(n_tr):\n",
    "            g_mat[i, j] = k_mat[i, j] * y_vec[i] * y_vec[j]\n",
    "    return g_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf0c78",
   "metadata": {},
   "source": [
    "```\n",
    "for con in enumerate(cons):\n",
    "    print(con)\n",
    "    \n",
    "(0, Inequality(Expression(CONVEX, NONNEGATIVE, (1, 1))))\n",
    "(1, Equality(Expression(AFFINE, UNKNOWN, ()), Constant(CONSTANT, ZERO, ())))\n",
    "(2, Inequality(Constant(CONSTANT, ZERO, ())))\n",
    "(3, Inequality(Variable((281,))))\n",
    "(4, Inequality(Expression(CONVEX, NONNEGATIVE, (1, 1))))\n",
    "(5, Equality(Expression(AFFINE, UNKNOWN, ()), Constant(CONSTANT, ZERO, ())))\n",
    "(6, Inequality(Constant(CONSTANT, ZERO, ())))\n",
    "(7, Inequality(Variable((281,))))\n",
    "(8, Inequality(Expression(CONVEX, NONNEGATIVE, (1, 1))))\n",
    "(9, Equality(Expression(AFFINE, UNKNOWN, ()), Constant(CONSTANT, ZERO, ())))\n",
    "(10, Inequality(Constant(CONSTANT, ZERO, ())))\n",
    "(11, Inequality(Variable((281,))))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfbe76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kernel_learning(K1, K2, K3, y_tr, rho)\n",
    "def kernel_learning(k_mats, y_tr, rho):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        Ks is list of (n_tr, n_tr) matrix.\n",
    "        y_tr is (n_tr,) array\n",
    "        \n",
    "    Output: \n",
    "        \n",
    "    Kernel learning for soft margin SVM. \n",
    "    Implementation of problem (5)\n",
    "    Use cvxpy.atoms.affine.psd_wrap for each G(\\hat K^l) matrix when \n",
    "    it appear in the constraints and in the objective\n",
    "    \"\"\"\n",
    "    \n",
    "    # r1 = np.trace(K1) \n",
    "    # r2 = np.trace(K2) \n",
    "    # r3 = np.trace(K3)\n",
    "    # r_l = [r1, r2, r3]\n",
    "    r_l = []\n",
    "    g_mats = []\n",
    "    for i in range(3):\n",
    "        r_l.append(np.trace(k_mats[i]))\n",
    "        g_mat = compute_g_mat(k_mats[i], y_tr)\n",
    "        g_mats.append(g_mat)\n",
    "    c = np.sum(r_l)\n",
    "    \n",
    "    \n",
    "    n_tr = len(y_tr)\n",
    "    lambda_ = cp.Variable(n_tr)\n",
    "    z = cp.Variable(1)\n",
    "    \n",
    "    obj = cp.Maximize(cp.sum(lambda_) - c*z)\n",
    "    cons = []\n",
    "    for l in range(3):\n",
    "        # Exception: Invalid dimensions for arguments.\n",
    "        cons.append(z * r_l[i] >= 1/ (2 * rho) * cp.quad_form(lambda_, psd_wrap(g_mats[i]))) # G1\n",
    "        cons.append(lambda_ @ y_tr == 0) # lambda_ * y_tr == 0\n",
    "        cons.extend([lambda_>=0, lambda_<=1])\n",
    "        \n",
    "    prob = cp.Problem(obj, cons)\n",
    "    prob.solve(solver=cp.MOSEK)\n",
    "    # print(\"lambda_.value =\", lambda_.value)\n",
    "    \n",
    "    # mu_opt_l (l=1,2,3) denote the optimal dual value of the constraint\n",
    "    mu_opt1 = cons[0].dual_value\n",
    "    mu_opt2 = cons[4].dual_value\n",
    "    mu_opt3 = cons[8].dual_value\n",
    "    print(\"mu_opt1 =\", mu_opt1)\n",
    "    print(\"mu_opt2 =\", mu_opt2)\n",
    "    print(\"mu_opt3 =\", mu_opt3)\n",
    "\n",
    "    # b = w^T x_i - y i x_i (n_d)\n",
    "    # w = 1/rho \\sum_{i=1}{m} \\lambda_i x_i y_i (m = n_tr sample number)\n",
    "    # from 4(c) b_opt is the dual variable of the constraint [1]\n",
    "    # print(cons[1].dual_value, cons[5].dual_value, cons[9].dual_value)\n",
    "    b_opt = np.max([cons[1].dual_value, cons[5].dual_value, cons[9].dual_value])\n",
    "    # for idx in range(12):\n",
    "    #     print(idx, cons[idx].dual_value)\n",
    "    \n",
    "    return mu_opt1, mu_opt2, mu_opt3, lambda_.value, b_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e4b57f",
   "metadata": {},
   "source": [
    "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
    "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
    "    Use ``multiply`` for elementwise multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "671cc261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_opt1 = [19.03475044]\n",
      "mu_opt2 = [0.72732141]\n",
      "mu_opt3 = [0.72502455]\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "def main_q4_b():\n",
    "    # \\rho = 2, p = 2, \\sigma = 0.5 and c = \\sum_{l=1}^3 \\mathrm{tr}(\\hat{K}^l)\n",
    "    data, labels = prepare_ionosphere_dataset()\n",
    "    \n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(data, labels, train_size=0.8)\n",
    "    \n",
    "    k_mats = compute_ks(x_tr)\n",
    "    \n",
    "    res = kernel_learning(k_mats, y_tr, rho=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_q4_b()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff54f9",
   "metadata": {},
   "source": [
    "### (c) Apply kernel trick for SVM prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c8a42",
   "metadata": {},
   "source": [
    "**(10 points)** Use the code skeletons `SVM_predict`(in `main.ipynb`) or `SVM_predict.m`.\n",
    "\n",
    "> The size of the dual QP is independent of the feature\n",
    "dimension D!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a7cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_predict(kernel, y_tr, y_te, lambda_opt, b_opt, rho):\n",
    "    \"\"\"\n",
    "    Predict function for kernel SVM. \n",
    "    See lecture slide 183.\n",
    "    \"\"\"\n",
    "    n_te = len(y_te)\n",
    "    n_tr = len(y_tr)\n",
    "    ...\n",
    "    \n",
    "    # wx = \\sum_{i=1}^{m} \\lambda_i y_i k_mat\n",
    "    wx = 0\n",
    "    y_pre = np.sign(1/rho * (wx - b_opt))\n",
    "    \n",
    "    acc = ...\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_q4_c():\n",
    "    # \\rho = 2, p = 2, \\sigma = 0.5 and c = \\sum_{l=1}^3 \\mathrm{tr}(\\hat{K}^l)\n",
    "    data, labels = prepare_ionosphere_dataset()\n",
    "    \n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(data, labels, train_size=0.8)\n",
    "    \n",
    "    k_mats = compute_ks(x_te)\n",
    "    \n",
    "    (mu_opt1, mu_opt2, mu_opt3, lambda_.value, b_opt) = kernel_learning(k_mats, y_tr, rho=2)\n",
    "    \n",
    "    k_mat_sum = mu_opt1 * k_mats[0] + mu_opt2 * k_mats[1] + mu_opt3 * k_mats[2]\n",
    "    \n",
    "    acc = svm_predict(k_mat_sum, y_tr, y_te, lambda_opt, b_opt, rho=2)\n",
    "    \n",
    "    print(\"Current accuracy is \", acc)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_q4_c()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028bf40",
   "metadata": {},
   "source": [
    "## B Repeat experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bd9a3b",
   "metadata": {},
   "source": [
    "**(5 points)** Repeat the steps 4(a)â€“(c) 100 times with different seeds for the random partition of the data intotraining and test sets, and report the average test accuracy (correct classification rate) to Table 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71868e56",
   "metadata": {},
   "source": [
    "| Kernel function  | $\\hat{k}^1$ | $\\hat{k}^2$ | $\\hat{k}^3$ | $\\sum_{l=1}^3 \\hat{k}^l$ |\n",
    "| ---------------- | ----------- | ----------- | ----------- | ------------------------ |\n",
    "| Average accuracy |             |             |             |                          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ca8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87f33c1a",
   "metadata": {},
   "source": [
    "## C Solve dual problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc4049",
   "metadata": {},
   "source": [
    "**(10  points)** For  each  of  the  100  training  and  test  sets  constructed  in  5.,  solve  (2)  using  the  kernels  functions $\\hat{k}^1$, $\\hat{k}^2$, and $\\hat{k}^3$, respectively, and report the average test accuracies in Table 1. Use the code skeletons `SVM_predict`(in `main.ipynb`) or `SVM_predict.m`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0a2cc",
   "metadata": {},
   "source": [
    "| Kernel function  | $\\hat{k}^1$ | $\\hat{k}^2$ | $\\hat{k}^3$ | $\\sum_{l=1}^3 \\hat{k}^l$ |\n",
    "| ---------------- | ----------- | ----------- | ----------- | ------------------------ |\n",
    "| Average accuracy |             |             |             |                          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e5e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b15debf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8afb19a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from cvxpy.atoms.affine.wraps import psd_wrap\n",
    "from read_data import *\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%       MGT - 418         %%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%      Convex Optimization - Project 2          %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%             2021-2022 Fall                    %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%      Learning the Kernel Function             %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9f60e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_fit(kernel, y_tr, rho):\n",
    "    \"\"\"\n",
    "    Dual of soft-margin SVM problem (2)\n",
    "    Use cvxpy.atoms.affine.psd_wrap for each G(\\hat K^l) matrix when it appear in the constraints and in the objective\n",
    "    \"\"\"\n",
    "    n_tr = len(y_tr)\n",
    "    G =  ...\n",
    "    lambda_ = cp.Variable(n_tr)\n",
    "    dual_obj = cp.Maximize(... cp.quad_form(lambda_, psd_wrap(G)))\n",
    "    cons = []\n",
    "    ...\n",
    "    prob = cp.Problem(dual_obj, cons)\n",
    "    prob.solve(solver=cp.MOSEK)\n",
    "    lambda_opt = lambda_.value\n",
    "    b_opt =  ...\n",
    "    return lambda_opt, b_opt\n",
    "\n",
    "\n",
    "def svm_predict(kernel, y_tr, y_te, lambda_opt, b_opt, rho):\n",
    "    \"\"\"\n",
    "    Predict function for kernel SVM. \n",
    "    See lecture slide 183.\n",
    "    \"\"\"\n",
    "    n_te = len(y_te)\n",
    "    n_tr = len(y_tr)\n",
    "    ...\n",
    "    acc = ...\n",
    "    return acc\n",
    "\n",
    "def kernel_learning(K1, K2, K3, y_tr, rho):\n",
    "    \"\"\"\n",
    "    Kernel learning for soft margin SVM. \n",
    "    Implementation of problem (5)\n",
    "    Use cvxpy.atoms.affine.psd_wrap for each G(\\hat K^l) matrix when it appear in the constraints and in the objective\n",
    "    \"\"\"\n",
    "    ...\n",
    "    r1 = np.trace(K1) \n",
    "    ...\n",
    "    lambda_ = cp.Variable(n_tr)\n",
    "    z = cp.Variable(1)\n",
    "    ...\n",
    "    \n",
    "    cons = []\n",
    "    cons.append(z * r1 >= 1/ (2 * rho) * cp.quad_form(lambda_, psd_wrap(G1)))\n",
    "    ...\n",
    "    ...\n",
    "    prob = cp.Problem(obj, cons)\n",
    "    prob.solve(solver=cp.MOSEK)\n",
    "\n",
    "    mu_opt1 = cons[0].dual_value\n",
    "    ...\n",
    "    b_opt = ....dual_value\n",
    "    return mu_opt1, mu_opt2, mu_opt3, lambda_.value, b_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0c9713b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_opt_kernel = []    \n",
    "acc_poly_kernel = []    \n",
    "acc_gauss_kernel = []    \n",
    "acc_linear_kernel = []    \n",
    "rho = 0.01\n",
    "# data, labels = prepare_ionosphere_dataset()\n",
    "for iters in range(100): \n",
    "    ## Please do not change the random seed.\n",
    "    np.random.seed(iters)\n",
    "    ### Training-test split\n",
    "    msk = np.random.rand(data_normalized.shape[0]) <=...\n",
    "    x_tr = data[...]\n",
    "    x_te = data[...]\n",
    "    y_tr = labels[...]\n",
    "    y_te = labels[...]\n",
    " \n",
    "    n_tr = y_tr.shape[0]\n",
    "    n_te = y_te.shape[0]\n",
    "    n_tr = x_tr.shape[0]\n",
    "    n_te = x_te.shape[0]\n",
    "    \n",
    "    x_all = np.vstack([x_tr, x_te])\n",
    "    n_all = x_all.shape[0]\n",
    "\n",
    "    ## Prepare the initial choice of kernels \n",
    "    # It is recommended to prepare the kernels for all the training and the test data\n",
    "    # Then, the kernel size will be (n_tr + n_te)x(n_tr + n_te).\n",
    "    # Use only the training block (like K1[0:n_tr, 0:n_tr] ) to learn the classifier \n",
    "    # (for the functions svm_fit and kernel_learning).\n",
    "    # When predicting you may use the whole kernel as it is. \n",
    "    K1 = ...\n",
    "    K2 = ...\n",
    "    K3 = ...\n",
    "\n",
    "    mu_opt1, mu_opt2, mu_opt3, lambda_opt, b_opt = kernel_learning(...)\n",
    "    opt_kernel = ...\n",
    "    acc_opt_kernel.append(svm_predict(...))\n",
    "    \n",
    "    lambda_opt, b_opt = svm_fit(...)\n",
    "    acc_poly_kernel.append(svm_predict(...))\n",
    "    \n",
    "    lambda_opt, b_opt = svm_fit(...)\n",
    "    acc_gauss_kernel.append(svm_predict(...))\n",
    "    \n",
    "    lambda_opt, b_opt = svm_fit(...)\n",
    "    acc_linear_kernel.append(svm_predict(...)\n",
    "    print('Iteration-->' + str(iters))\n",
    "print('Average dual accuracy with optimal kernel is ' + str(np.mean(acc_opt_kernel)))\n",
    "print('Average dual accuracy with polynomial kernel is ' + str(np.mean(acc_poly_kernel)))\n",
    "print('Average dual accuracy with gaussian kernel is ' + str(np.mean(acc_gauss_kernel)))\n",
    "print('Average dual accuracy with linear kernel is ' + str(np.mean(acc_linear_kernel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c834cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
