{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71ad60ca",
   "metadata": {},
   "source": [
    "# Radar Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5145a2",
   "metadata": {},
   "source": [
    "## A Radar Classification Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a41617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import cvxpy as cp\n",
    "from cvxpy.atoms.affine.wraps import psd_wrap\n",
    "from read_data import *\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%       MGT - 418         %%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%      Convex Optimization - Project 2          %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%             2021-2022 Fall                    %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%      Learning the Kernel Function             %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89c9907",
   "metadata": {},
   "source": [
    "### (a) Read & Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bc34d0",
   "metadata": {},
   "source": [
    "**(5 points)** Read the data file ionosphere.data into memory by using the scriptsreaddata.pyorreaddata.m.Use the code skeletonsmain.ipnyb or main.m to randomly select 80% of the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "729b41d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = prepare_ionosphere_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b795ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_data import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cabc1712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0\n",
      "[[1.0 0.97588 -0.10602 0.94601 -0.208 0.92806 -0.2835 0.85996 -0.27342\n",
      "  0.79766 -0.47929 0.78225 -0.50764 0.74628 -0.61436 0.57945 -0.68086\n",
      "  0.37852 -0.73641 0.36324 -0.76562 0.31898 -0.79753 0.22792 -0.81634\n",
      "  0.13659 -0.8251 0.04606 -0.82395 -0.04262 -0.81318 -0.13832 -0.80975]]\n",
      "#1\n",
      "[[1.0 -0.205 0.2875 0.23 0.1 0.2825 0.3175 0.3225 0.35 0.36285 -0.34617\n",
      "  0.0925 0.275 -0.095 0.21 -0.0875 0.235 -0.34187 0.31408 -0.48 -0.08\n",
      "  0.29908 0.33176 -0.58 -0.24 0.3219 -0.28475 -0.47 0.185 -0.27104\n",
      "  -0.31228 0.40445 0.0305]]\n",
      "#2\n",
      "[[1.0 1.0 0.5782 1.0 -1.0 1.0 -1.0 1.0 -1.0 1.0 -1.0 1.0 -1.0 1.0 -1.0\n",
      "  1.0 -1.0 1.0 -1.0 1.0 -0.62796 1.0 -1.0 1.0 -1.0 1.0 -1.0 1.0 -1.0 1.0\n",
      "  -1.0 1.0 -1.0]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"#{}\".format(i))\n",
    "    # data_train, data_test, labels_train, labels_test\n",
    "    data_train, _, _, _ = train_test_split(data, labels, train_size=0.8, random_seed=i)\n",
    "    print(data_train[:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91059b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 35)\n",
      "Unique values in 2nd column: [0]\n",
      "(351, 34)\n",
      "281\n"
     ]
    }
   ],
   "source": [
    "# just testing\n",
    "df = pd.read_csv('ionosphere.data', sep=\",\", header=None)\n",
    "data_array = np.array(df)\n",
    "print(np.shape(data_array))\n",
    "# delete the second row\n",
    "print(\"Unique values in 2nd column:\", np.unique(data_array[:,1]))\n",
    "data_array = np.delete(data_array, 1, 1)\n",
    "print(np.shape(data_array))\n",
    "print(round(np.shape(data_array)[0]*0.8))\n",
    "labels = data_array[:, -1]\n",
    "labels[labels == 'g'] = -1\n",
    "labels[labels == 'b'] = 1\n",
    "data_array = data_array[:, :-1]\n",
    "data_normalized = data_array / data_array.max(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396849b",
   "metadata": {},
   "source": [
    "- reference links\n",
    "\n",
    "    - https://stackoverflow.com/questions/3674409/how-to-split-partition-a-dataset-into-training-and-test-datasets-for-e-g-cros\n",
    "    - https://towardsdatascience.com/stop-using-numpy-random-seed-581a9972805f\n",
    "    - https://stackoverflow.com/questions/49555991/can-i-create-a-local-numpy-random-seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a016f",
   "metadata": {},
   "source": [
    "### (b) Define kernel function & Solve QCQP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f054940",
   "metadata": {},
   "source": [
    "**(15 points)** Define polynomial, Gaussian, and linear kernel function, and construct the kernel matrices $\\hat{K}^l,\\ l = 1,2,3$, for all training samples\n",
    "Solve the QCQP in (5) for $\\rho = 2$, $p = 2$, $\\sigma = 2$ and $c = \\sum_{l=1}^3 \\mathrm{tr}(\\hat{K}^l) $ with CVXPY and MOSEK in Python or with YALMIP and GUROBI in MATLAB, and record the optimal dualvariables $\\mu_1^*$, $\\mu_2^*$, and $\\mu_3^*$. Use the code skeletons `kernel_learning` (in `main.ipynb`) or `kernel_learning.m`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d5d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_kernel(x, y):\n",
    "    return np.inner(x, y)\n",
    "\n",
    "\n",
    "def gauss_kernel(x, y, sigma=0.5):\n",
    "    return np.exp(-np.sqrt(la.norm(x - y) ** 2 / (2 * sigma ** 2)))\n",
    "\n",
    "\n",
    "def poly_kernel(x, y, dimension=2, offset=1):\n",
    "    return (offset + np.inner(x, y)) ** dimension\n",
    "\n",
    "\n",
    "def compute_k_mat(X, kernel):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        X is an n_tr x n_feat matrix.\n",
    "        kernel is a string with values 'linear', 'rfb', or 'poly'\n",
    "            'linear': k(u,v) = u'*v.\n",
    "            'gaussian':    k(u,v) = exp(-||u - v||^2 / (2*sigma)).\n",
    "            'poly':   k(u,v) = (1 + u'*v)**degree.\n",
    "            degree is a positive integer.\n",
    "    Output:\n",
    "        k_mat, an n_tr x n_tr matrix.\n",
    "    \"\"\"\n",
    "    n_samples, _ = X.shape\n",
    "    k_mat = np.zeros((n_samples, n_samples))\n",
    "    for i, x_i in enumerate(X):\n",
    "        for j, x_j in enumerate(X):\n",
    "            if kernel == \"linear\":\n",
    "                k_mat[i, j] = linear_kernel(x_i, x_j)\n",
    "            elif kernel == \"gaussian\":\n",
    "                k_mat[i, j] = gauss_kernel(x_i, x_j)\n",
    "            elif kernel == \"poly\":\n",
    "                k_mat[i, j] = poly_kernel(x_i, x_j)\n",
    "    return k_mat\n",
    "\n",
    "\n",
    "def compute_ks(x_mat):\n",
    "    \"\"\"compute all three kernel matrix\"\"\"\n",
    "    kernels = [\"poly\", \"gaussian\", \"linear\"]\n",
    "    k_mats = []\n",
    "    for k in kernels:\n",
    "        mat = compute_k_mat(x_mat, k)\n",
    "        k_mats.append(mat)\n",
    "    return k_mats\n",
    "\n",
    "\n",
    "def compute_g_mat(k_mat, y_vec):\n",
    "    n_tr = len(y_vec)\n",
    "    g_mat = np.zeros((n_tr, n_tr))\n",
    "    for i in range(n_tr):\n",
    "        for j in range(n_tr):\n",
    "            g_mat[i, j] = k_mat[i, j] * y_vec[i] * y_vec[j]\n",
    "    return g_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf0c78",
   "metadata": {},
   "source": [
    "```\n",
    "for con in enumerate(cons):\n",
    "    print(con)\n",
    "    \n",
    "(0, Inequality(Expression(CONVEX, NONNEGATIVE, (1, 1))))\n",
    "(1, Equality(Expression(AFFINE, UNKNOWN, ()), Constant(CONSTANT, ZERO, ())))\n",
    "(2, Inequality(Constant(CONSTANT, ZERO, ())))\n",
    "(3, Inequality(Variable((281,))))\n",
    "(4, Inequality(Expression(CONVEX, NONNEGATIVE, (1, 1))))\n",
    "(5, Equality(Expression(AFFINE, UNKNOWN, ()), Constant(CONSTANT, ZERO, ())))\n",
    "(6, Inequality(Constant(CONSTANT, ZERO, ())))\n",
    "(7, Inequality(Variable((281,))))\n",
    "(8, Inequality(Expression(CONVEX, NONNEGATIVE, (1, 1))))\n",
    "(9, Equality(Expression(AFFINE, UNKNOWN, ()), Constant(CONSTANT, ZERO, ())))\n",
    "(10, Inequality(Constant(CONSTANT, ZERO, ())))\n",
    "(11, Inequality(Variable((281,))))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfbe76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kernel_learning(K1, K2, K3, y_tr, rho)\n",
    "def kernel_learning(k_mats, y_tr, rho):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        Ks is list of (n_tr, n_tr) matrix.\n",
    "        y_tr is (n_tr,) array\n",
    "        \n",
    "    Output: \n",
    "        \n",
    "    Kernel learning for soft margin SVM. \n",
    "    Implementation of problem (5)\n",
    "    Use cvxpy.atoms.affine.psd_wrap for each G(\\hat K^l) matrix when \n",
    "    it appear in the constraints and in the objective\n",
    "    \"\"\"\n",
    "    \n",
    "    # r1 = np.trace(K1) \n",
    "    # r2 = np.trace(K2) \n",
    "    # r3 = np.trace(K3)\n",
    "    # r_l = [r1, r2, r3]\n",
    "    r_l = []\n",
    "    g_mats = []\n",
    "    for i in range(3):\n",
    "        r_l.append(np.trace(k_mats[i]))\n",
    "        g_mat = compute_g_mat(k_mats[i], y_tr)\n",
    "        g_mats.append(g_mat)\n",
    "    c = np.sum(r_l)\n",
    "    \n",
    "    \n",
    "    n_tr = len(y_tr)\n",
    "    lambda_ = cp.Variable(n_tr)\n",
    "    z = cp.Variable(1)\n",
    "    \n",
    "    obj = cp.Maximize(cp.sum(lambda_) - c*z)\n",
    "    cons = []\n",
    "    for l in range(3):\n",
    "        # Exception: Invalid dimensions for arguments.\n",
    "        cons.append(z * r_l[i] >= 1/ (2 * rho) * cp.quad_form(lambda_, psd_wrap(g_mats[i]))) # G1\n",
    "        cons.append(lambda_ @ y_tr == 0) # lambda_ * y_tr == 0\n",
    "        cons.extend([lambda_>=0, lambda_<=1])\n",
    "        \n",
    "    prob = cp.Problem(obj, cons)\n",
    "    prob.solve(solver=cp.MOSEK)\n",
    "    # print(\"lambda_.value =\", lambda_.value)\n",
    "    \n",
    "    # mu_opt_l (l=1,2,3) denote the optimal dual value of the constraint\n",
    "    mu_opt1 = cons[0].dual_value\n",
    "    mu_opt2 = cons[4].dual_value\n",
    "    mu_opt3 = cons[8].dual_value\n",
    "    print(\"mu_opt1 =\", mu_opt1)\n",
    "    print(\"mu_opt2 =\", mu_opt2)\n",
    "    print(\"mu_opt3 =\", mu_opt3)\n",
    "\n",
    "    # b = w^T x_i - y i x_i (n_d)\n",
    "    # w = 1/rho \\sum_{i=1}{m} \\lambda_i x_i y_i (m = n_tr sample number)\n",
    "    # from 4(c) b_opt is the dual variable of the constraint [1]\n",
    "    # print(cons[1].dual_value, cons[5].dual_value, cons[9].dual_value)\n",
    "    b_opt = np.max([cons[1].dual_value, cons[5].dual_value, cons[9].dual_value])\n",
    "    # for idx in range(12):\n",
    "    #     print(idx, cons[idx].dual_value)\n",
    "    \n",
    "    return mu_opt1, mu_opt2, mu_opt3, lambda_.value, b_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e4b57f",
   "metadata": {},
   "source": [
    "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
    "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
    "    Use ``multiply`` for elementwise multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "671cc261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_opt1 = [19.03475044]\n",
      "mu_opt2 = [0.72732141]\n",
      "mu_opt3 = [0.72502455]\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "def main_q4_b():\n",
    "    # \\rho = 2, p = 2, \\sigma = 0.5 and c = \\sum_{l=1}^3 \\mathrm{tr}(\\hat{K}^l)\n",
    "    data, labels = prepare_ionosphere_dataset()\n",
    "    \n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(data, labels, train_size=0.8)\n",
    "    \n",
    "    k_mats = compute_ks(x_tr)\n",
    "    \n",
    "    res = kernel_learning(k_mats, y_tr, rho=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_q4_b()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff54f9",
   "metadata": {},
   "source": [
    "### (c) Apply kernel trick for SVM prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40c8a42",
   "metadata": {},
   "source": [
    "**(10 points)** Use the code skeletons `SVM_predict`(in `main.ipynb`) or `SVM_predict.m`.\n",
    "\n",
    "> The size of the dual QP is independent of the feature\n",
    "dimension D!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a7cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_predict(kernel, y_tr, y_te, lambda_opt, b_opt, rho):\n",
    "    \"\"\"\n",
    "    Predict function for kernel SVM. \n",
    "    See lecture slide 183.\n",
    "    \"\"\"\n",
    "    n_te = len(y_te)\n",
    "    n_tr = len(y_tr)\n",
    "    ...\n",
    "    \n",
    "    # wx = \\sum_{i=1}^{m} \\lambda_i y_i k_mat\n",
    "    wx = 0\n",
    "    y_pre = np.sign(1/rho * (wx - b_opt))\n",
    "    \n",
    "    acc = ...\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_q4_c():\n",
    "    # \\rho = 2, p = 2, \\sigma = 0.5 and c = \\sum_{l=1}^3 \\mathrm{tr}(\\hat{K}^l)\n",
    "    data, labels = prepare_ionosphere_dataset()\n",
    "    \n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(data, labels, train_size=0.8)\n",
    "    \n",
    "    k_mats = compute_ks(x_te)\n",
    "    \n",
    "    (mu_opt1, mu_opt2, mu_opt3, lambda_.value, b_opt) = kernel_learning(k_mats, y_tr, rho=2)\n",
    "    \n",
    "    k_mat_sum = mu_opt1 * k_mats[0] + mu_opt2 * k_mats[1] + mu_opt3 * k_mats[2]\n",
    "    \n",
    "    acc = svm_predict(k_mat_sum, y_tr, y_te, lambda_opt, b_opt, rho=2)\n",
    "    \n",
    "    print(\"Current accuracy is \", acc)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_q4_c()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028bf40",
   "metadata": {},
   "source": [
    "## B Repeat experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bd9a3b",
   "metadata": {},
   "source": [
    "**(5 points)** Repeat the steps 4(a)–(c) 100 times with different seeds for the random partition of the data intotraining and test sets, and report the average test accuracy (correct classification rate) to Table 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71868e56",
   "metadata": {},
   "source": [
    "| Kernel function  | $\\hat{k}^1$ | $\\hat{k}^2$ | $\\hat{k}^3$ | $\\sum_{l=1}^3 \\hat{k}^l$ |\n",
    "| ---------------- | ----------- | ----------- | ----------- | ------------------------ |\n",
    "| Average accuracy |             |             |             |                          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696ca8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87f33c1a",
   "metadata": {},
   "source": [
    "## C Solve dual problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dc4049",
   "metadata": {},
   "source": [
    "**(10  points)** For  each  of  the  100  training  and  test  sets  constructed  in  5.,  solve  (2)  using  the  kernels  functions $\\hat{k}^1$, $\\hat{k}^2$, and $\\hat{k}^3$, respectively, and report the average test accuracies in Table 1. Use the code skeletons `SVM_predict`(in `main.ipynb`) or `SVM_predict.m`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0a2cc",
   "metadata": {},
   "source": [
    "| Kernel function  | $\\hat{k}^1$ | $\\hat{k}^2$ | $\\hat{k}^3$ | $\\sum_{l=1}^3 \\hat{k}^l$ |\n",
    "| ---------------- | ----------- | ----------- | ----------- | ------------------------ |\n",
    "| Average accuracy |             |             |             |                          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e5e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b15debf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8afb19a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from cvxpy.atoms.affine.wraps import psd_wrap\n",
    "from read_data import *\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%       MGT - 418         %%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%      Convex Optimization - Project 2          %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%             2021-2022 Fall                    %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%      Learning the Kernel Function             %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9f60e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_fit(kernel, y_tr, rho):\n",
    "    \"\"\"\n",
    "    Dual of soft-margin SVM problem (2)\n",
    "    Use cvxpy.atoms.affine.psd_wrap for each G(\\hat K^l) matrix when it appear in the constraints and in the objective\n",
    "    \"\"\"\n",
    "    n_tr = len(y_tr)\n",
    "    G =  ...\n",
    "    lambda_ = cp.Variable(n_tr)\n",
    "    dual_obj = cp.Maximize(... cp.quad_form(lambda_, psd_wrap(G)))\n",
    "    cons = []\n",
    "    ...\n",
    "    prob = cp.Problem(dual_obj, cons)\n",
    "    prob.solve(solver=cp.MOSEK)\n",
    "    lambda_opt = lambda_.value\n",
    "    b_opt =  ...\n",
    "    return lambda_opt, b_opt\n",
    "\n",
    "\n",
    "def svm_predict(kernel, y_tr, y_te, lambda_opt, b_opt, rho):\n",
    "    \"\"\"\n",
    "    Predict function for kernel SVM. \n",
    "    See lecture slide 183.\n",
    "    \"\"\"\n",
    "    n_te = len(y_te)\n",
    "    n_tr = len(y_tr)\n",
    "    ...\n",
    "    acc = ...\n",
    "    return acc\n",
    "\n",
    "def kernel_learning(K1, K2, K3, y_tr, rho):\n",
    "    \"\"\"\n",
    "    Kernel learning for soft margin SVM. \n",
    "    Implementation of problem (5)\n",
    "    Use cvxpy.atoms.affine.psd_wrap for each G(\\hat K^l) matrix when it appear in the constraints and in the objective\n",
    "    \"\"\"\n",
    "    ...\n",
    "    r1 = np.trace(K1) \n",
    "    ...\n",
    "    lambda_ = cp.Variable(n_tr)\n",
    "    z = cp.Variable(1)\n",
    "    ...\n",
    "    \n",
    "    cons = []\n",
    "    cons.append(z * r1 >= 1/ (2 * rho) * cp.quad_form(lambda_, psd_wrap(G1)))\n",
    "    ...\n",
    "    ...\n",
    "    prob = cp.Problem(obj, cons)\n",
    "    prob.solve(solver=cp.MOSEK)\n",
    "\n",
    "    mu_opt1 = cons[0].dual_value\n",
    "    ...\n",
    "    b_opt = ....dual_value\n",
    "    return mu_opt1, mu_opt2, mu_opt3, lambda_.value, b_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0c9713b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_opt_kernel = []    \n",
    "acc_poly_kernel = []    \n",
    "acc_gauss_kernel = []    \n",
    "acc_linear_kernel = []    \n",
    "rho = 0.01\n",
    "# data, labels = prepare_ionosphere_dataset()\n",
    "for iters in range(100): \n",
    "    ## Please do not change the random seed.\n",
    "    np.random.seed(iters)\n",
    "    ### Training-test split\n",
    "    msk = np.random.rand(data_normalized.shape[0]) <=...\n",
    "    x_tr = data[...]\n",
    "    x_te = data[...]\n",
    "    y_tr = labels[...]\n",
    "    y_te = labels[...]\n",
    " \n",
    "    n_tr = y_tr.shape[0]\n",
    "    n_te = y_te.shape[0]\n",
    "    n_tr = x_tr.shape[0]\n",
    "    n_te = x_te.shape[0]\n",
    "    \n",
    "    x_all = np.vstack([x_tr, x_te])\n",
    "    n_all = x_all.shape[0]\n",
    "\n",
    "    ## Prepare the initial choice of kernels \n",
    "    # It is recommended to prepare the kernels for all the training and the test data\n",
    "    # Then, the kernel size will be (n_tr + n_te)x(n_tr + n_te).\n",
    "    # Use only the training block (like K1[0:n_tr, 0:n_tr] ) to learn the classifier \n",
    "    # (for the functions svm_fit and kernel_learning).\n",
    "    # When predicting you may use the whole kernel as it is. \n",
    "    K1 = ...\n",
    "    K2 = ...\n",
    "    K3 = ...\n",
    "\n",
    "    mu_opt1, mu_opt2, mu_opt3, lambda_opt, b_opt = kernel_learning(...)\n",
    "    opt_kernel = ...\n",
    "    acc_opt_kernel.append(svm_predict(...))\n",
    "    \n",
    "    lambda_opt, b_opt = svm_fit(...)\n",
    "    acc_poly_kernel.append(svm_predict(...))\n",
    "    \n",
    "    lambda_opt, b_opt = svm_fit(...)\n",
    "    acc_gauss_kernel.append(svm_predict(...))\n",
    "    \n",
    "    lambda_opt, b_opt = svm_fit(...)\n",
    "    acc_linear_kernel.append(svm_predict(...)\n",
    "    print('Iteration-->' + str(iters))\n",
    "print('Average dual accuracy with optimal kernel is ' + str(np.mean(acc_opt_kernel)))\n",
    "print('Average dual accuracy with polynomial kernel is ' + str(np.mean(acc_poly_kernel)))\n",
    "print('Average dual accuracy with gaussian kernel is ' + str(np.mean(acc_gauss_kernel)))\n",
    "print('Average dual accuracy with linear kernel is ' + str(np.mean(acc_linear_kernel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c834cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
